{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "Num GPUs available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "print(tf.__version__)\n",
    "print('Num GPUs available: ', len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dense,GlobalMaxPooling2D,MaxPool2D\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the image datasets for this institution. Also import the most recent global model weights, which will be used to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43374 images belonging to 2 classes.\n",
      "Found 21361 images belonging to 2 classes.\n",
      "Found 10790 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "global_weights_dir = r\"C:\\Documents\\Global_Model\\global_model_0X.h5\"\n",
    "data_dir = r'C:\\Documents\\Institution_X'\n",
    "train_dir = os.path.join(data_dir, 'train_seq')\n",
    "test_dir = os.path.join(data_dir, 'test_seq')\n",
    "\n",
    "batch_size = 32\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# create a data generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, horizontal_flip = True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, class_mode='binary', batch_size=batch_size,target_size = (224, 224))\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, class_mode='binary', batch_size=batch_size,target_size=(224, 224))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to construct the VGG16 Convolutional Neural Network (CNN) with our layer alterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "\n",
    "    #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "    base_model=VGG16(weights='imagenet',include_top=False,input_shape=input_shape) \n",
    "\n",
    "    #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "    x=base_model.output\n",
    "    x=keras.layers.GlobalMaxPooling2D()(x)\n",
    "    x=keras.layers.Dense(1024,activation='relu')(x)\n",
    "    x=keras.layers.Dense(1024,activation='relu')(x)\n",
    "    x=keras.layers.Dropout(0.25)(x)\n",
    "    x=keras.layers.Dense(1024,activation='relu')(x) #dense layer 2\n",
    "    x=keras.layers.Dense(512,activation='relu')(x) #dense layer 3\n",
    "    preds=keras.layers.Dense(1,activation='sigmoid')(x) #final layer with sigmoid activation function\n",
    "    \n",
    "    model=keras.Model(inputs=base_model.input,outputs=preds)\n",
    "    model.trainable = True\n",
    "\n",
    "    # We want to set the first 20 layers of the network to be non-trainable\n",
    "    for layer in model.layers[:16]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[16:]:\n",
    "        layer.trainable=True\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for tuning the parameters and initialize, fit, and compile the CNN model. The global model weights are loaded into the model after it is compiled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model,base_weights_dir,train_history_dir):\n",
    "    \n",
    "    steps_per_epoch = int(len(train_generator))\n",
    "    validation_steps = int(len(test_generator))\n",
    "\n",
    "    checkpointer = keras.callbacks.ModelCheckpoint(base_weights_dir, monitor='val_accuracy',mode='max',save_best_only=True, save_weights_only=True)\n",
    "\n",
    "    adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',keras.metrics.Recall(),keras.metrics.Precision()])\n",
    "    \n",
    "    #load the global model weights into the model\n",
    "    model.load_weights(global_weights_dir, by_name=True)\n",
    "    \n",
    "    reduce_lr_loss = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=5, verbose=1, min_delta=1e-4, mode='max')\n",
    "    earlyStopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, verbose=0, mode='max')\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=r'C:\\Documents\\Institution_X\\iter_Y\\experiment')\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=steps_per_epoch,\n",
    "                epochs = 100,\n",
    "                validation_data=test_generator,\n",
    "                validation_steps=validation_steps,\n",
    "                verbose=1,\n",
    "                callbacks=[checkpointer,reduce_lr_loss,earlyStopping,tensorboard_callback]\n",
    "\n",
    "            )\n",
    "\n",
    "\n",
    "    with open(train_history_dir, 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)\n",
    "\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the functions to construct and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#save directories\n",
    "base_weights_dir = r'C:\\Documents\\Institution_X\\iter_Y\\weights_directory\\instX.h5'\n",
    "train_history_dir = r'C:\\Documents\\Institution_X\\iter_Y\\train_history_directory\\instx.pickle'\n",
    "\n",
    "model = create_model(input_shape)\n",
    "history = fit_model(model,base_weights_dir,train_history_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
